{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# setup\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pprint\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# set root directory\n",
    "ROOT_DIR = os.path.abspath(os.curdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# workflow\n",
    "### 1. load data\n",
    "### 2. normalize\n",
    "### 3. extract features\n",
    "### 4. classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load face data\n",
    "from util.data_utils import load_data\n",
    "X_train, y_train, X_train_origin, X_train_face_cords, \\\n",
    "X_test, y_test, X_test_origin, X_test_face_cords = load_data(verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(140,)\n",
      "(140,)\n",
      "(140, 576, 768, 3)\n",
      "(140, 4)\n",
      "(104,)\n",
      "(104,)\n",
      "(104, 576, 768, 3)\n",
      "(104, 4)\n"
     ]
    }
   ],
   "source": [
    "# sanity check\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_train_origin.shape)\n",
    "print(X_train_face_cords.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "print(X_test_origin.shape)\n",
    "print(X_test_face_cords.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for normalizing, calculate meidian of width, height of images\n",
    "width = []\n",
    "height = []\n",
    "for img in X_train:\n",
    "    width.append(img.shape[1])\n",
    "    height.append(img.shape[0])\n",
    "median_size = (int(np.around(np.median(width))), int(np.around(np.median(height))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize input data\n",
    "from util.data_utils import normalize_image\n",
    "for i, img in enumerate(X_train):\n",
    "    X_train[i] = normalize_image(img, median_size)\n",
    "for i, img in enumerate(X_test):\n",
    "    X_test[i] = normalize_image(img, median_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 featurizing completed.\n",
      "20 featurizing completed.\n",
      "30 featurizing completed.\n",
      "40 featurizing completed.\n",
      "50 featurizing completed.\n",
      "60 featurizing completed.\n",
      "70 featurizing completed.\n",
      "80 featurizing completed.\n",
      "90 featurizing completed.\n",
      "100 featurizing completed.\n",
      "110 featurizing completed.\n",
      "120 featurizing completed.\n",
      "130 featurizing completed.\n",
      "140 featurizing completed.\n",
      "==========================\n",
      "All featurizing completed.\n"
     ]
    }
   ],
   "source": [
    "# extract features of train images\n",
    "from util.feature import extract_feature\n",
    "X_train_feats = extract_feature(X_train, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 featurizing completed.\n",
      "20 featurizing completed.\n",
      "30 featurizing completed.\n",
      "40 featurizing completed.\n",
      "50 featurizing completed.\n",
      "60 featurizing completed.\n",
      "70 featurizing completed.\n",
      "80 featurizing completed.\n",
      "90 featurizing completed.\n",
      "100 featurizing completed.\n",
      "104 featurizing completed.\n",
      "==========================\n",
      "All featurizing completed.\n"
     ]
    }
   ],
   "source": [
    "# extract features of train images\n",
    "X_test_feats = extract_feature(X_test, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardization\n",
    "\"\"\"\n",
    "feats_mean = np.mean(X_train_feats, axis = 0, keepdims=True, dtype='int32')\n",
    "X_train_feats_stded = X_train_feats - feats_mean\n",
    "X_test_feats_stded = X_test_feats - feats_mean\n",
    "feats_std = np.round(np.std(X_train_feats, axis = 0,  keepdims=True)).astype(\"int\")\n",
    "X_train_feats_stded = X_train_feats - feats_std\n",
    "X_test_feats_stded = X_test_feats - feats_std\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_svm_train_feats = [] \n",
    "for feat in X_train_feats:\n",
    "    tmp = {}\n",
    "    for i, value in enumerate(feat):\n",
    "        tmp[i+1] = value\n",
    "    X_svm_train_feats.append(tmp)\n",
    "X_svm_test_feats = [] \n",
    "for feat in X_test_feats:\n",
    "    tmp = {}\n",
    "    for i, value in enumerate(feat):\n",
    "        tmp[i+1] = value\n",
    "    X_svm_test_feats.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from classifiers.svm import SVM\n",
    "# convert names of y_train, y_test labels into integer\n",
    "y_train_num = [ int(val[-1:]) for val in y_train]\n",
    "y_test_num = [ int(val[-1:]) for val in y_test]\n",
    "svm = SVM()\n",
    "# train svm\n",
    "svm.train(X_svm_train_feats, y_train_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 100% (140/140) (classification)\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0]\n"
     ]
    }
   ],
   "source": [
    "# predict train data\n",
    "y_train_pred = svm.predict(X_svm_train_feats, y_train_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 12.5% (13/104) (classification)\n",
      "[7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 6.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0]\n"
     ]
    }
   ],
   "source": [
    "# predict test data\n",
    "y_test_pred = svm.predict(X_svm_test_feats, y_test_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing result\n",
    "from util.data_utils import visualize_pred\n",
    "y_svm_pred_ids = [\"ID_\" + str(int(i)) for i in y_test_pred]\n",
    "visualize_pred(X_test_face_cords, X_test_origin, y_svm_pred_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nearest Neighbor Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from classifiers.nearest_neighbor import NearestNeighbor\n",
    "nn = NearestNeighbor(X_train_feats, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# predict train data\n",
    "y_train_pred = nn.predict(X_train_feats)\n",
    "accuracy = np.mean(y_train_pred == y_train)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.875\n"
     ]
    }
   ],
   "source": [
    "# predict test data\n",
    "y_test_pred = nn.predict(X_test_feats)\n",
    "accuracy = np.mean(y_test_pred == y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing\n",
    "from util.data_utils import visualize_pred\n",
    "y_nn_pred_ids = y_test_pred\n",
    "visualize_pred(X_test_face_cords, X_test_origin, y_nn_pred_ids)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
