{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# setup\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pprint\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# set root directory\n",
    "ROOT_DIR = os.path.abspath(os.curdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# workflow\n",
    "### 1. load data\n",
    "### 2. normalize\n",
    "### 3. extract features\n",
    "### 4. classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load face data\n",
    "from util.data_utils import load_data\n",
    "X_train, y_train, X_train_origin, X_train_face_cords, \\\n",
    "X_test, y_test, X_test_origin, X_test_face_cords = load_data(verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(140,)\n",
      "(140,)\n",
      "(140, 576, 768, 3)\n",
      "(140, 4)\n",
      "(104,)\n",
      "(104,)\n",
      "(104, 576, 768, 3)\n",
      "(104, 4)\n"
     ]
    }
   ],
   "source": [
    "# sanity check\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_train_origin.shape)\n",
    "print(X_train_face_cords.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "print(X_test_origin.shape)\n",
    "print(X_test_face_cords.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LBP feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for normalizing, calculate meidian of width, height of images\n",
    "width = []\n",
    "height = []\n",
    "for img in X_train:\n",
    "    width.append(img.shape[1])\n",
    "    height.append(img.shape[0])\n",
    "median_size = (int(np.around(np.median(width))), int(np.around(np.median(height))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arbitrary set image size\n",
    "median_size = (256, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize input data\n",
    "from util.data_utils import normalize_image\n",
    "for i, img in enumerate(X_train):\n",
    "    X_train[i] = normalize_image(img, median_size)\n",
    "for i, img in enumerate(X_test):\n",
    "    X_test[i] = normalize_image(img, median_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 featurizing completed.\n",
      "20 featurizing completed.\n",
      "30 featurizing completed.\n",
      "40 featurizing completed.\n",
      "50 featurizing completed.\n",
      "60 featurizing completed.\n",
      "70 featurizing completed.\n",
      "80 featurizing completed.\n",
      "90 featurizing completed.\n",
      "100 featurizing completed.\n",
      "110 featurizing completed.\n",
      "120 featurizing completed.\n",
      "130 featurizing completed.\n",
      "140 featurizing completed.\n",
      "==========================\n",
      "All featurizing completed.\n"
     ]
    }
   ],
   "source": [
    "# extract features from train images\n",
    "from features.Lbp import extract_feature_lbp\n",
    "X_train_feats = extract_feature_lbp(X_train, block_size = 3, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 featurizing completed.\n",
      "20 featurizing completed.\n",
      "30 featurizing completed.\n",
      "40 featurizing completed.\n",
      "50 featurizing completed.\n",
      "60 featurizing completed.\n",
      "70 featurizing completed.\n",
      "80 featurizing completed.\n",
      "90 featurizing completed.\n",
      "100 featurizing completed.\n",
      "104 featurizing completed.\n",
      "==========================\n",
      "All featurizing completed.\n"
     ]
    }
   ],
   "source": [
    "# extract features of test images\n",
    "X_test_feats = extract_feature_lbp(X_test, block_size = 3, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HOG feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recommended size : 128x64\n",
    "median_size = (128, 64)\n",
    "from features.Hog import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize input size\n",
    "from util.data_utils import normalize_image\n",
    "for i, img in enumerate(X_train):\n",
    "    X_train[i] = normalize_image(img, median_size)\n",
    "for i, img in enumerate(X_test):\n",
    "    X_test[i] = normalize_image(img, median_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract features from train images \n",
    "X_train_feats = extract_feature(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract features from test images\n",
    "X_test_feats = extract_feature(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from classifiers.svm import SVM\n",
    "# convert names of y_train, y_test labels into integer\n",
    "y_train_num = [ int(val[-1:]) for val in y_train]\n",
    "y_test_num = [ int(val[-1:]) for val in y_test]\n",
    "svm = SVM()\n",
    "# train svm\n",
    "#params = [0, 2, 1, 0.01]\n",
    "svm.train(X_train_feats, y_train_num)#, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 100% (140/140) (classification)\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0]\n"
     ]
    }
   ],
   "source": [
    "# predict train data\n",
    "y_train_pred = svm.predict(X_train_feats, y_train_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 86.5385% (90/104) (classification)\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 4.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 1.0, 3.0, 3.0, 3.0, 6.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 6.0, 6.0, 6.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 3.0, 4.0, 4.0, 4.0, 4.0, 5.0, 5.0, 5.0, 5.0, 5.0, 6.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 7.0, 7.0, 7.0, 7.0, 7.0, 3.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0]\n"
     ]
    }
   ],
   "source": [
    "# predict test data\n",
    "y_test_pred = svm.predict(X_test_feats, y_test_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# visualizing result\n",
    "from util.data_utils import visualize_pred\n",
    "y_svm_pred_ids = [\"ID_\" + str(int(i)) for i in y_test_pred]\n",
    "visualize_pred(X_test_face_cords, X_test_origin, y_svm_pred_ids, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nearest Neighbor Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from classifiers.nearest_neighbor import NearestNeighbor\n",
    "nn = NearestNeighbor(X_train_feats, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# predict train data\n",
    "y_train_pred = nn.predict(X_train_feats)\n",
    "accuracy = np.mean(y_train_pred == y_train)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9326923076923077\n"
     ]
    }
   ],
   "source": [
    "# predict test data\n",
    "y_test_pred = nn.predict(X_test_feats)\n",
    "accuracy = np.mean(y_test_pred == y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# visualizing\n",
    "from util.data_utils import visualize_pred\n",
    "y_nn_pred_ids = y_test_pred\n",
    "visualize_pred(X_test_face_cords, X_test_origin, y_nn_pred_ids, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
